{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CmO1WEDPp1xy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "3sd_AEJspQJg",
    "outputId": "a5b451be-7dba-490e-8884-cd89be6f7ba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  323k  100  323k    0     0  1366k      0 --:--:-- --:--:-- --:--:-- 1360k\n",
      "name,red,green,blue\n",
      "parakeet,174,182,87\n",
      "saddle brown,88,52,1\n",
      "cucumber crush,222,237,215\n",
      "pool blue,134,194,201\n",
      "distance,98,110,130\n",
      "light urple,179,111,246\n",
      "east side,172,145,206\n",
      "florida seashells,250,228,199\n",
      "paris,145,167,189\n"
     ]
    }
   ],
   "source": [
    "# Download the colors dataset\n",
    "if not os.path.exists('colors.csv'):\n",
    "  !curl -O 'https://raw.githubusercontent.com/random-forests/datasets/master/colors.csv'\n",
    "!head colors.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mG0WnNZtmxul",
    "outputId": "9f2c106f-df60-459e-8760-4c59edaab5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14157 colors downloaded\n",
      "For example ('parakeet', 174, 182, 87)\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "colors_rgb = []\n",
    "csv_reader = csv.reader(open('colors.csv'), delimiter=',')\n",
    "next(csv_reader) # Remove the header\n",
    "for row in csv_reader:\n",
    "    name, r, g, b = row[0].lower().strip(), int(row[1]), int(row[2]), int(row[3])\n",
    "    colors_rgb.append((name, r, g, b))\n",
    "print(len(colors_rgb), 'colors downloaded')\n",
    "print('For example', colors_rgb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PdIWQdlBrZXA",
    "outputId": "8f72c845-a6c2-4867-998f-93192b5c43ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parakeet 174 182 87\n"
     ]
    }
   ],
   "source": [
    "# In this experiment, we will train a char-baed RNN to generate a line of text\n",
    "# that resembles this dataset (we'll treat each line as a string)\n",
    "sentences = []\n",
    "for row in colors_rgb:\n",
    "  line = ' '.join([str(part) for part in row])\n",
    "  sentences.append(line)\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "Q_o2oIUNuyWZ",
    "outputId": "8b14e14b-896b-4b8c-e967-f9115a7af507"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 38\n",
      "[' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '<pad>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for our char-based RNN\n",
    "chars = set()\n",
    "for sentence in sentences:\n",
    "  for char in sentence:\n",
    "    chars.add(char)\n",
    "    \n",
    "# add a special char for padding\n",
    "chars.add('<pad>')\n",
    "\n",
    "vocab = sorted(set(chars))\n",
    "\n",
    "# Create a mapping from unique characters to indices\n",
    "char2idx = {u : i for i, u in enumerate(vocab)}\n",
    "idx2char = {i : u for i, u in enumerate(vocab)}\n",
    "\n",
    "# Vocab size\n",
    "vocab_size = len(vocab)\n",
    "print('vocab size:', vocab_size)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p5sdKRJ6rp8I",
    "outputId": "58b6d6b9-6cd8-4f7e-bfbf-948a2e5cec03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized sentence [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8]\n"
     ]
    }
   ],
   "source": [
    "# vectorize the text\n",
    "text_int = []\n",
    "for sentence in sentences:\n",
    "  int_sentence = [] \n",
    "  for c in sentence:\n",
    "    int_sentence.append(char2idx[c])\n",
    "  text_int.append(int_sentence)\n",
    "print('Vectorized sentence', text_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "0g6Do15As4yQ",
    "outputId": "271b7d06-4be7-40c1-ef84-fce274e437fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded sentences [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
     ]
    }
   ],
   "source": [
    "# pad sentences to max_length\n",
    "max_length = 40\n",
    "for sentence in text_int:\n",
    "  while (len(sentence) < max_length):\n",
    "    sentence.append(char2idx['<pad>'])\n",
    "print('Padded sentences', text_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-y87WF_Fw1kJ",
    "outputId": "a77b0722-9fab-405f-a61d-1f68025c9da8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truncated sentences [27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
     ]
    }
   ],
   "source": [
    "# truncate all sentences to max_length\n",
    "for i in range(len(text_int)):\n",
    "  sentence = text_int[i]\n",
    "  if len(sentence) > max_length:\n",
    "    text_int[i] = sentence[:max_length]\n",
    "print(\"Truncated sentences\", text_int[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "9fVyQeZ6m6B5",
    "outputId": "bbb39771-48cf-4698-efb8-cbc73611c03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'a', 'r', 'a', 'k', 'e', 'e', 't', ' ', '1', '7', '4', ' ', '1', '8', '2', ' ', '8', '7', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "t = []\n",
    "for i in text_int[0]:\n",
    "  ts = idx2char[i]\n",
    "  t.append(ts)\n",
    "\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "mwu3FgSpxNWT",
    "outputId": "47624bb3-038b-4c3c-e5d7-195d38dd41bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First training example, target\n",
      "[27, 12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n",
      "[12, 29, 12, 22, 16, 16, 31, 0, 2, 8, 5, 0, 2, 9, 3, 0, 9, 8, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11]\n"
     ]
    }
   ],
   "source": [
    "# Create training examples / targets\n",
    "input_text = []\n",
    "target_text = []\n",
    "\n",
    "for i in range(len(text_int)):\n",
    "  inps = text_int[i][:max_length-1]\n",
    "  targ = text_int[i][1:max_length]\n",
    "  input_text.append(inps)\n",
    "  target_text.append(targ)\n",
    "  \n",
    "print(\"First training example, target\")  \n",
    "print(input_text[0])\n",
    "print(target_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjyeDrvGzl8E"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_text, target_text))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TT8ed7cu0w-z"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "  rnn = tf.keras.layers.CuDNNGRU\n",
    "else:\n",
    "  import functools\n",
    "  rnn = functools.partial(\n",
    "    tf.keras.layers.GRU, recurrent_activation='sigmoid')\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, units):\n",
    "    super(Model, self).__init__()\n",
    "    self.units = units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.rnn=rnn(units,\n",
    "                 return_sequences=True, \n",
    "                 recurrent_initializer='glorot_uniform',\n",
    "                 stateful=True)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "  def call(self, x):\n",
    "    emb = self.embedding(x)\n",
    "    rnn = self.rnn(emb)\n",
    "    pred = self.fc(rnn)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jA8Pssrh1NKE"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension \n",
    "# Here, this is basically just a trick to avoid having \n",
    "# to one-hot encode the characters\n",
    "# I don't think it will add much otherwise\n",
    "# this would be more useful if we had a much larger vocabulary\n",
    "embedding_dim = 128\n",
    "\n",
    "# Number of RNN units\n",
    "units = 256\n",
    "\n",
    "model = Model(vocab_size, embedding_dim, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrSRbSQk1Rcz"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer()\n",
    "\n",
    "# Using sparse_softmax_cross_entropy so that we don't have to create one-hot vectors\n",
    "def loss_function(labels, logits):\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "-AILeTt71UXr",
    "outputId": "261a4128-01a6-4a59-d96f-dc1d36e71019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      multiple                  4864      \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  multiple                  295680    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              multiple                  9766      \n",
      "=================================================================\n",
      "Total params: 310,310\n",
      "Trainable params: 310,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.build(tf.TensorShape([BATCH_SIZE, max_length]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gjYtdulr8ukK"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "# Checkpoint instance\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "GkLMi8GI1c9b",
    "outputId": "e3dc1f14-0a9f-4e76-9988-7955c220f981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 3.6310\n",
      "Epoch 1 Batch 100 Loss 1.4911\n",
      "Epoch 1 Batch 200 Loss 1.1814\n",
      "Epoch 1 Loss 1.1875\n",
      "Time for epoch 156.5130491256714 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.4675\n",
      "Epoch 2 Batch 100 Loss 1.1340\n",
      "Epoch 2 Batch 200 Loss 1.0965\n",
      "Epoch 2 Loss 1.0601\n",
      "Time for epoch 157.8417410850525 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.1983\n",
      "Epoch 3 Batch 100 Loss 1.0693\n",
      "Epoch 3 Batch 200 Loss 1.0776\n",
      "Epoch 3 Loss 1.0313\n",
      "Time for epoch 158.27889919281006 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.0688\n",
      "Epoch 4 Batch 100 Loss 1.0303\n",
      "Epoch 4 Batch 200 Loss 1.0239\n",
      "Epoch 4 Loss 0.9648\n",
      "Time for epoch 159.6379473209381 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.0529\n",
      "Epoch 5 Batch 100 Loss 0.9710\n",
      "Epoch 5 Batch 200 Loss 0.9596\n",
      "Epoch 5 Loss 0.9096\n",
      "Time for epoch 157.2077078819275 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.0075\n",
      "Epoch 6 Batch 100 Loss 0.9046\n",
      "Epoch 6 Batch 200 Loss 0.9178\n",
      "Epoch 6 Loss 0.9491\n",
      "Time for epoch 160.18744587898254 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.0172\n",
      "Epoch 7 Batch 100 Loss 0.9150\n",
      "Epoch 7 Batch 200 Loss 0.9628\n",
      "Epoch 7 Loss 0.8753\n",
      "Time for epoch 160.03268218040466 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.9447\n",
      "Epoch 8 Batch 100 Loss 0.8719\n",
      "Epoch 8 Batch 200 Loss 0.8877\n",
      "Epoch 8 Loss 0.8125\n",
      "Time for epoch 160.30718660354614 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.9301\n",
      "Epoch 9 Batch 100 Loss 0.8322\n",
      "Epoch 9 Batch 200 Loss 0.8644\n",
      "Epoch 9 Loss 0.8368\n",
      "Time for epoch 157.7542543411255 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.9226\n",
      "Epoch 10 Batch 100 Loss 0.8329\n",
      "Epoch 10 Batch 200 Loss 0.8261\n",
      "Epoch 10 Loss 0.8444\n",
      "Time for epoch 158.87678265571594 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    # initializing the hidden state at the start of every epoch\n",
    "    # initally hidden is None\n",
    "    hidden = model.reset_states()\n",
    "    \n",
    "    for (batch, (input_seq, target_seq)) in enumerate(dataset):\n",
    "          with tf.GradientTape() as tape:\n",
    "              predictions = model(input_seq)\n",
    "              loss = loss_function(target_seq, predictions)\n",
    "              \n",
    "          grads = tape.gradient(loss, model.variables)\n",
    "          optimizer.apply_gradients(zip(grads, model.variables))\n",
    "\n",
    "          if batch % 100 == 0:\n",
    "              print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch+1,\n",
    "                                                            batch,\n",
    "                                                            loss))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch+1, loss))\n",
    "    print ('Time for epoch {} sec\\n'.format(time.time() - start))\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "0U_cmqGP8dwg",
    "outputId": "77b13a57-d27d-4c2c-9fc3-27007c7b8466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\t\t     ckpt-5.data-00000-of-00001\n",
      "ckpt-10.data-00000-of-00001  ckpt-5.index\n",
      "ckpt-10.index\t\t     ckpt-6.data-00000-of-00001\n",
      "ckpt-1.data-00000-of-00001   ckpt-6.index\n",
      "ckpt-1.index\t\t     ckpt-7.data-00000-of-00001\n",
      "ckpt-2.data-00000-of-00001   ckpt-7.index\n",
      "ckpt-2.index\t\t     ckpt-8.data-00000-of-00001\n",
      "ckpt-3.data-00000-of-00001   ckpt-8.index\n",
      "ckpt-3.index\t\t     ckpt-9.data-00000-of-00001\n",
      "ckpt-4.data-00000-of-00001   ckpt-9.index\n",
      "ckpt-4.index\n"
     ]
    }
   ],
   "source": [
    "!ls {checkpoint_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0K3VLTVT81rt"
   },
   "outputs": [],
   "source": [
    "# This is a hack to let us use the model with a different \n",
    "# batch size later\n",
    "model = Model(vocab_size, embedding_dim, units)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "id": "RczLSuZN3oBH",
    "outputId": "012b879d-303f-44c0-b32e-b8cf4afce9e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there gray 173 158 157\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAFdCAYAAABcnZV9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyoXYkZP8dVAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7faf6d803c18>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluation step (generating text using the learned model)\n",
    "\n",
    "# Number of characters to generate\n",
    "num_generate = max_length\n",
    "\n",
    "# You can change the start string to experiment\n",
    "start_string = random.choice(string.ascii_lowercase)\n",
    "\n",
    "# Converting our start string to numbers (vectorizing) \n",
    "input_eval = [char2idx[s] for s in start_string]\n",
    "input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "# Empty string to store our results\n",
    "text_generated = []\n",
    "\n",
    "# Low temperatures results in more predictable text.\n",
    "# Higher temperatures results in more surprising text.\n",
    "# Experiment to find the best setting.\n",
    "temperature = 0.5\n",
    "\n",
    "# Here batch size == 1\n",
    "model.reset_states()\n",
    "for i in range(num_generate):\n",
    "    predictions = model(input_eval)\n",
    "    # remove the batch dimension\n",
    "    predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "    # using a multinomial distribution to predict the word returned by the model\n",
    "    predictions = predictions / temperature\n",
    "    predicted_id = tf.multinomial(predictions, num_samples=1)[-1,0].numpy()\n",
    "    \n",
    "    # We pass the predicted word as the next input to the model\n",
    "    # along with the previous hidden state\n",
    "    input_eval = tf.expand_dims([predicted_id], 0)\n",
    "    \n",
    "    text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "generated_color = start_string + ''.join(text_generated).replace('<pad>', '')\n",
    "print(generated_color)\n",
    "\n",
    "try:\n",
    "  parts = generated_color.split()\n",
    "  r = float(parts[-3])\n",
    "  g = float(parts[-2])\n",
    "  b = float(parts[-1])\n",
    "  plt.clf()\n",
    "  _ = plt.imshow([[(r, g, b)]])\n",
    "  _ = plt.axis('off')\n",
    "  _ = plt.title(generated_color, fontsize=18)\n",
    "except:\n",
    "  print('unable to parse color')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "8_colorbot_generate_starter.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
